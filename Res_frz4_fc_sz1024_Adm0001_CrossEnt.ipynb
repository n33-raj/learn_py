{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "**Connecting Colab to G-Drive**"
      ],
      "metadata": {
        "id": "u8sJZ4PxGa0K"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qt6DZqxEtaOJ",
        "outputId": "8da0d028-94fa-4a58-f74a-7c5d01d8b653"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Moving to Path Folder & Installing  Dependencies**"
      ],
      "metadata": {
        "id": "pBbWuOxDHR6N"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZS-iieWXwgTv",
        "outputId": "6400e9ad-ee01-4916-8795-a64301c6e379"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/Resnet18\n"
          ]
        }
      ],
      "source": [
        "%cd /content/drive/MyDrive/Resnet18"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "uy9fx-w-tzIY"
      },
      "outputs": [],
      "source": [
        "## Importing dependencies\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets, transforms, models\n",
        "import os"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WNRf0AypvWGK",
        "outputId": "08a4c09e-f72f-47e8-e45f-e2fe5a9729b5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " animal_sgd_0001_model.pth\t\t    dataset_animals.zip\n",
            " APHU6500062_20240601072327.jpg\t\t    elephnt00005.jpg\n",
            " cat0005.jpg\t\t\t\t    model.pth\n",
            " Container_cls_Adam_10Ep_sz1024_model.pth   Res0.ipynb\n",
            " Container_cls_Adam_60Ep_model.pth\t    Res_frz4_fc_sz1024_Adm0001_CrossEnt.ipynb\n",
            " container_sgd_0001_model.pth\t\t    Res_frz4_fc_sz256_Adm0001_CrossEnt.ipynb\n",
            " dataset\t\t\t\t   'Screenshot (534).png'\n",
            " dataset_animals\t\t\t    Test\n"
          ]
        }
      ],
      "source": [
        "!ls"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Data Transformations For Data Augmentation & Normalization**"
      ],
      "metadata": {
        "id": "NE6lBbfeHv9z"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "5RRp0bLsxfy6"
      },
      "outputs": [],
      "source": [
        "data_transforms = {\n",
        "    'train': transforms.Compose([\n",
        "        transforms.RandomResizedCrop(1024),                   # Random crop to 1024x1024\n",
        "        transforms.RandomHorizontalFlip(),                    # Random horizontal flip\n",
        "        transforms.RandomAffine(degrees=0, shear=20, scale=(0.8, 1.2)),  # Shear and zoom (scale) augmentation\n",
        "        transforms.ToTensor(),                                # Transform to pixel values [0,1]\n",
        "        transforms.Normalize([0.485, 0.456, 0.406],           # Mean normalization\n",
        "                             [0.229, 0.224, 0.225])           # Standard deviation normalization\n",
        "    ]),\n",
        "    'val': transforms.Compose([\n",
        "        transforms.Resize(1024),                              # Resize the shorter side to 1024\n",
        "        transforms.CenterCrop(1024),                          # Crop the center to 1024x1024\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize([0.485, 0.456, 0.406],\n",
        "                             [0.229, 0.224, 0.225])\n",
        "    ]),\n",
        "}\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Dataset Path and Dataloader**"
      ],
      "metadata": {
        "id": "aqpAAGINIA_D"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bx6VbNs8yCiC",
        "outputId": "daaf3eb5-837f-4ef0-bd80-a4d3350b5800"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'train': 353, 'val': 89}\n",
            "['Clean', 'Garbage', 'Incomplete', 'Not Clean']\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:617: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "## Dataset path\n",
        "data_dir = '/content/drive/MyDrive/Resnet18/dataset'\n",
        "\n",
        "## Data loaders\n",
        "image_datasets = {x: datasets.ImageFolder(os.path.join(data_dir, x), data_transforms[x]) for x in ['train', 'val']}\n",
        "\n",
        "dataloaders = {x: torch.utils.data.DataLoader(image_datasets[x], batch_size=4, shuffle=True, num_workers=4) for x in ['train', 'val']}\n",
        "dataset_sizes = {x: len(image_datasets[x]) for x in ['train', 'val']}\n",
        "print(dataset_sizes)         ## To print dataset size\n",
        "\n",
        "class_names = image_datasets['train'].classes\n",
        "print(class_names)            ## To print classes names"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Loading Pre-trained ResNet-18, Freezing All Layers Except layer4 & fc, Adding custom dense layers, Loss Function and Optimizer**"
      ],
      "metadata": {
        "id": "dL8NnyIpIeJF"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6sjJM8Yr0Beh",
        "outputId": "194ebf34-9c75-4a9b-8b62-86e1405a17b0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n",
            "Downloading: \"https://download.pytorch.org/models/resnet18-f37072fd.pth\" to /root/.cache/torch/hub/checkpoints/resnet18-f37072fd.pth\n",
            "100%|██████████| 44.7M/44.7M [00:01<00:00, 38.5MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Parameters that gonna be trained:\n",
            "\t layer4.0.conv1.weight True\n",
            "\t layer4.0.bn1.weight True\n",
            "\t layer4.0.bn1.bias True\n",
            "\t layer4.0.conv2.weight True\n",
            "\t layer4.0.bn2.weight True\n",
            "\t layer4.0.bn2.bias True\n",
            "\t layer4.0.downsample.0.weight True\n",
            "\t layer4.0.downsample.1.weight True\n",
            "\t layer4.0.downsample.1.bias True\n",
            "\t layer4.1.conv1.weight True\n",
            "\t layer4.1.bn1.weight True\n",
            "\t layer4.1.bn1.bias True\n",
            "\t layer4.1.conv2.weight True\n",
            "\t layer4.1.bn2.weight True\n",
            "\t layer4.1.bn2.bias True\n",
            "\t fc.weight True\n",
            "\t fc.bias True\n",
            "Total parameters to train: 17\n"
          ]
        }
      ],
      "source": [
        "## Loading pre-trained ResNet-18 model\n",
        "model = models.resnet18(pretrained=True)\n",
        "\n",
        "## Freeze all layers except 'layer4' and 'fc'\n",
        "for name, param in model.named_parameters():\n",
        "    if \"layer4\" not in name and 'fc' not in name:\n",
        "        param.requires_grad = False\n",
        "\n",
        "## Parameters that gonna be trained\n",
        "print(\"Parameters that gonna be trained:\")\n",
        "parameters_to_train = []\n",
        "for name, param in model.named_parameters():\n",
        "    if param.requires_grad:\n",
        "        parameters_to_train.append(param)\n",
        "        print(\"\\t\", name,param.requires_grad)\n",
        "print(\"Total parameters to train:\", len(parameters_to_train))\n",
        "\n",
        "## Adding 4 FC layers\n",
        "# Modify the final fully connected layer\n",
        "num_ftrs = model.fc.in_features  # Number of features from the ResNet-18 backbone\n",
        "model.fc = nn.Sequential(\n",
        "    nn.Linear(num_ftrs, 1024),    # First dense layer\n",
        "    nn.ReLU(),                   # Activation for the first dense layer\n",
        "    nn.Dropout(0.5),           # Dropout layer\n",
        "    nn.Linear(1024, 512),        # Second dense layer\n",
        "    nn.ReLU(),                   # Activation for the second dense layer\n",
        "    nn.Dropout(0.5),\n",
        "    nn.Linear(512, 256),         # Third dense layer\n",
        "    nn.ReLU(),                   # Activation for the third dense layer\n",
        "    nn.Linear(256, len(class_names)),  # Fourth dense layer\n",
        "    nn.Softmax(dim=1)            # Softmax activation for output probabilities\n",
        ")\n",
        "\n",
        "\n",
        "## Loss function & Optimizer\n",
        "criterion = nn.CrossEntropyLoss()       ## Loss function\n",
        "# optimizer = optim.SGD(model.parameters(), lr=5e-7, momentum=0.9)     ## Optimizer & LR = 5x10^-7\n",
        "optimizer = optim.Adam(model.parameters(), lr=1e-4, betas=(0.9, 0.999))\n",
        "\n",
        "## Move the model to the GPU if available\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = model.to(device)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Model Summary**"
      ],
      "metadata": {
        "id": "W2OR7s3bJGF5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torchinfo\n",
        "\n",
        "from torchinfo import summary\n",
        "\n",
        "## This model is our trained model\n",
        "summary(model, input_size=(4, 3, 1024, 1024))  ## Batch size, No. of channels (RGB), Input size"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n7u3SZDzGIuv",
        "outputId": "7103f37f-19c3-485d-f68b-c9960a7cbee5"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting torchinfo\n",
            "  Downloading torchinfo-1.8.0-py3-none-any.whl.metadata (21 kB)\n",
            "Downloading torchinfo-1.8.0-py3-none-any.whl (23 kB)\n",
            "Installing collected packages: torchinfo\n",
            "Successfully installed torchinfo-1.8.0\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "==========================================================================================\n",
              "Layer (type:depth-idx)                   Output Shape              Param #\n",
              "==========================================================================================\n",
              "ResNet                                   [4, 4]                    --\n",
              "├─Conv2d: 1-1                            [4, 64, 512, 512]         (9,408)\n",
              "├─BatchNorm2d: 1-2                       [4, 64, 512, 512]         (128)\n",
              "├─ReLU: 1-3                              [4, 64, 512, 512]         --\n",
              "├─MaxPool2d: 1-4                         [4, 64, 256, 256]         --\n",
              "├─Sequential: 1-5                        [4, 64, 256, 256]         --\n",
              "│    └─BasicBlock: 2-1                   [4, 64, 256, 256]         --\n",
              "│    │    └─Conv2d: 3-1                  [4, 64, 256, 256]         (36,864)\n",
              "│    │    └─BatchNorm2d: 3-2             [4, 64, 256, 256]         (128)\n",
              "│    │    └─ReLU: 3-3                    [4, 64, 256, 256]         --\n",
              "│    │    └─Conv2d: 3-4                  [4, 64, 256, 256]         (36,864)\n",
              "│    │    └─BatchNorm2d: 3-5             [4, 64, 256, 256]         (128)\n",
              "│    │    └─ReLU: 3-6                    [4, 64, 256, 256]         --\n",
              "│    └─BasicBlock: 2-2                   [4, 64, 256, 256]         --\n",
              "│    │    └─Conv2d: 3-7                  [4, 64, 256, 256]         (36,864)\n",
              "│    │    └─BatchNorm2d: 3-8             [4, 64, 256, 256]         (128)\n",
              "│    │    └─ReLU: 3-9                    [4, 64, 256, 256]         --\n",
              "│    │    └─Conv2d: 3-10                 [4, 64, 256, 256]         (36,864)\n",
              "│    │    └─BatchNorm2d: 3-11            [4, 64, 256, 256]         (128)\n",
              "│    │    └─ReLU: 3-12                   [4, 64, 256, 256]         --\n",
              "├─Sequential: 1-6                        [4, 128, 128, 128]        --\n",
              "│    └─BasicBlock: 2-3                   [4, 128, 128, 128]        --\n",
              "│    │    └─Conv2d: 3-13                 [4, 128, 128, 128]        (73,728)\n",
              "│    │    └─BatchNorm2d: 3-14            [4, 128, 128, 128]        (256)\n",
              "│    │    └─ReLU: 3-15                   [4, 128, 128, 128]        --\n",
              "│    │    └─Conv2d: 3-16                 [4, 128, 128, 128]        (147,456)\n",
              "│    │    └─BatchNorm2d: 3-17            [4, 128, 128, 128]        (256)\n",
              "│    │    └─Sequential: 3-18             [4, 128, 128, 128]        (8,448)\n",
              "│    │    └─ReLU: 3-19                   [4, 128, 128, 128]        --\n",
              "│    └─BasicBlock: 2-4                   [4, 128, 128, 128]        --\n",
              "│    │    └─Conv2d: 3-20                 [4, 128, 128, 128]        (147,456)\n",
              "│    │    └─BatchNorm2d: 3-21            [4, 128, 128, 128]        (256)\n",
              "│    │    └─ReLU: 3-22                   [4, 128, 128, 128]        --\n",
              "│    │    └─Conv2d: 3-23                 [4, 128, 128, 128]        (147,456)\n",
              "│    │    └─BatchNorm2d: 3-24            [4, 128, 128, 128]        (256)\n",
              "│    │    └─ReLU: 3-25                   [4, 128, 128, 128]        --\n",
              "├─Sequential: 1-7                        [4, 256, 64, 64]          --\n",
              "│    └─BasicBlock: 2-5                   [4, 256, 64, 64]          --\n",
              "│    │    └─Conv2d: 3-26                 [4, 256, 64, 64]          (294,912)\n",
              "│    │    └─BatchNorm2d: 3-27            [4, 256, 64, 64]          (512)\n",
              "│    │    └─ReLU: 3-28                   [4, 256, 64, 64]          --\n",
              "│    │    └─Conv2d: 3-29                 [4, 256, 64, 64]          (589,824)\n",
              "│    │    └─BatchNorm2d: 3-30            [4, 256, 64, 64]          (512)\n",
              "│    │    └─Sequential: 3-31             [4, 256, 64, 64]          (33,280)\n",
              "│    │    └─ReLU: 3-32                   [4, 256, 64, 64]          --\n",
              "│    └─BasicBlock: 2-6                   [4, 256, 64, 64]          --\n",
              "│    │    └─Conv2d: 3-33                 [4, 256, 64, 64]          (589,824)\n",
              "│    │    └─BatchNorm2d: 3-34            [4, 256, 64, 64]          (512)\n",
              "│    │    └─ReLU: 3-35                   [4, 256, 64, 64]          --\n",
              "│    │    └─Conv2d: 3-36                 [4, 256, 64, 64]          (589,824)\n",
              "│    │    └─BatchNorm2d: 3-37            [4, 256, 64, 64]          (512)\n",
              "│    │    └─ReLU: 3-38                   [4, 256, 64, 64]          --\n",
              "├─Sequential: 1-8                        [4, 512, 32, 32]          --\n",
              "│    └─BasicBlock: 2-7                   [4, 512, 32, 32]          --\n",
              "│    │    └─Conv2d: 3-39                 [4, 512, 32, 32]          1,179,648\n",
              "│    │    └─BatchNorm2d: 3-40            [4, 512, 32, 32]          1,024\n",
              "│    │    └─ReLU: 3-41                   [4, 512, 32, 32]          --\n",
              "│    │    └─Conv2d: 3-42                 [4, 512, 32, 32]          2,359,296\n",
              "│    │    └─BatchNorm2d: 3-43            [4, 512, 32, 32]          1,024\n",
              "│    │    └─Sequential: 3-44             [4, 512, 32, 32]          132,096\n",
              "│    │    └─ReLU: 3-45                   [4, 512, 32, 32]          --\n",
              "│    └─BasicBlock: 2-8                   [4, 512, 32, 32]          --\n",
              "│    │    └─Conv2d: 3-46                 [4, 512, 32, 32]          2,359,296\n",
              "│    │    └─BatchNorm2d: 3-47            [4, 512, 32, 32]          1,024\n",
              "│    │    └─ReLU: 3-48                   [4, 512, 32, 32]          --\n",
              "│    │    └─Conv2d: 3-49                 [4, 512, 32, 32]          2,359,296\n",
              "│    │    └─BatchNorm2d: 3-50            [4, 512, 32, 32]          1,024\n",
              "│    │    └─ReLU: 3-51                   [4, 512, 32, 32]          --\n",
              "├─AdaptiveAvgPool2d: 1-9                 [4, 512, 1, 1]            --\n",
              "├─Sequential: 1-10                       [4, 4]                    --\n",
              "│    └─Linear: 2-9                       [4, 1024]                 525,312\n",
              "│    └─ReLU: 2-10                        [4, 1024]                 --\n",
              "│    └─Dropout: 2-11                     [4, 1024]                 --\n",
              "│    └─Linear: 2-12                      [4, 512]                  524,800\n",
              "│    └─ReLU: 2-13                        [4, 512]                  --\n",
              "│    └─Dropout: 2-14                     [4, 512]                  --\n",
              "│    └─Linear: 2-15                      [4, 256]                  131,328\n",
              "│    └─ReLU: 2-16                        [4, 256]                  --\n",
              "│    └─Linear: 2-17                      [4, 4]                    1,028\n",
              "│    └─Softmax: 2-18                     [4, 4]                    --\n",
              "==========================================================================================\n",
              "Total params: 12,358,980\n",
              "Trainable params: 9,576,196\n",
              "Non-trainable params: 2,782,784\n",
              "Total mult-adds (Units.GIGABYTES): 151.60\n",
              "==========================================================================================\n",
              "Input size (MB): 50.33\n",
              "Forward/backward pass size (MB): 3321.95\n",
              "Params size (MB): 49.44\n",
              "Estimated Total Size (MB): 3421.71\n",
              "=========================================================================================="
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XeLxrKEImPr2",
        "outputId": "f1d3036d-840e-466d-fb4a-6b13fa184056"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ResNet(\n",
            "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
            "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (relu): ReLU(inplace=True)\n",
            "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
            "  (layer1): Sequential(\n",
            "    (0): BasicBlock(\n",
            "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (1): BasicBlock(\n",
            "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "  )\n",
            "  (layer2): Sequential(\n",
            "    (0): BasicBlock(\n",
            "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (downsample): Sequential(\n",
            "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (1): BasicBlock(\n",
            "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "  )\n",
            "  (layer3): Sequential(\n",
            "    (0): BasicBlock(\n",
            "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (downsample): Sequential(\n",
            "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (1): BasicBlock(\n",
            "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "  )\n",
            "  (layer4): Sequential(\n",
            "    (0): BasicBlock(\n",
            "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (downsample): Sequential(\n",
            "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (1): BasicBlock(\n",
            "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "  )\n",
            "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
            "  (fc): Sequential(\n",
            "    (0): Linear(in_features=512, out_features=1024, bias=True)\n",
            "    (1): ReLU()\n",
            "    (2): Dropout(p=0.5, inplace=False)\n",
            "    (3): Linear(in_features=1024, out_features=512, bias=True)\n",
            "    (4): ReLU()\n",
            "    (5): Dropout(p=0.5, inplace=False)\n",
            "    (6): Linear(in_features=512, out_features=256, bias=True)\n",
            "    (7): ReLU()\n",
            "    (8): Linear(in_features=256, out_features=4, bias=True)\n",
            "    (9): Softmax(dim=1)\n",
            "  )\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Training The Model**"
      ],
      "metadata": {
        "id": "KAr53kSSJSVN"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 408
        },
        "id": "7CCDtcAB2G7k",
        "outputId": "126ac791-5adb-43b0-833f-4caf5ff3a164"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 1/50\n",
            "--------------------------------------------------\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-7-4240f14eeece>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_grad_enabled\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mphase\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'train'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m                 \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m                 \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpreds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m                 \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1735\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1736\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1737\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1746\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1748\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torchvision/models/resnet.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    283\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    284\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 285\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    286\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    287\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torchvision/models/resnet.py\u001b[0m in \u001b[0;36m_forward_impl\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    269\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbn1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    270\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 271\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmaxpool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    272\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    273\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1735\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1736\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1737\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1746\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1748\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/pooling.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    211\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    212\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 213\u001b[0;31m         return F.max_pool2d(\n\u001b[0m\u001b[1;32m    214\u001b[0m             \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkernel_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/_jit_internal.py\u001b[0m in \u001b[0;36mfn\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    622\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mif_true\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    623\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 624\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mif_false\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    625\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    626\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mif_true\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__doc__\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mif_false\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__doc__\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36m_max_pool2d\u001b[0;34m(input, kernel_size, stride, padding, dilation, ceil_mode, return_indices)\u001b[0m\n\u001b[1;32m    828\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mstride\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    829\u001b[0m         \u001b[0mstride\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mannotate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mList\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 830\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_pool2d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkernel_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstride\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdilation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mceil_mode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    831\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    832\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "## Dictionaries to store train and val loss and accuracy\n",
        "history = {'train_loss': [], 'val_loss': [], 'train_acc': [], 'val_acc': []}\n",
        "\n",
        "num_epochs = 50                    ## Number of Epochs for training\n",
        "for epoch in range(num_epochs):\n",
        "    print(f\"\\nEpoch {epoch + 1}/{num_epochs}\")\n",
        "    print('-' * 50)\n",
        "\n",
        "    for phase in ['train', 'val']:\n",
        "        if phase == 'train':\n",
        "            model.train()\n",
        "        else:\n",
        "            model.eval()\n",
        "\n",
        "        running_loss = 0.0\n",
        "        running_corrects = 0\n",
        "\n",
        "        for inputs, labels in dataloaders[phase]:\n",
        "            inputs = inputs.to(device)\n",
        "            labels = labels.to(device)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            with torch.set_grad_enabled(phase == 'train'):\n",
        "                outputs = model(inputs)\n",
        "                _, preds = torch.max(outputs, 1)\n",
        "                loss = criterion(outputs, labels)\n",
        "\n",
        "                if phase == 'train':\n",
        "                    loss.backward()\n",
        "                    optimizer.step()\n",
        "\n",
        "            running_loss += loss.item() * inputs.size(0)\n",
        "            running_corrects += torch.sum(preds == labels.data)\n",
        "\n",
        "        epoch_loss = running_loss / dataset_sizes[phase]\n",
        "        epoch_acc = running_corrects.double() / dataset_sizes[phase]\n",
        "\n",
        "        print(f'{phase} Loss: {epoch_loss:.4f} Acc: {epoch_acc:.4f}')\n",
        "\n",
        "        ## Store the metrics in the history dictionary\n",
        "        if phase == 'train':\n",
        "            history['train_loss'].append(epoch_loss)\n",
        "            history['train_acc'].append(epoch_acc.item())\n",
        "        else:\n",
        "            history['val_loss'].append(epoch_loss)\n",
        "            history['val_acc'].append(epoch_acc.item())\n",
        "\n",
        "print(\"\\nCongrats Training complete!\")\n",
        "\n",
        "## Plot Loss and Accuracy\n",
        "epochs = range(1, num_epochs + 1)\n",
        "\n",
        "plt.figure(figsize=(14, 5))\n",
        "\n",
        "\n",
        "## Plot Loss\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(epochs, history['train_loss'], label='Training Loss')\n",
        "plt.plot(epochs, history['val_loss'], label='Validation Loss')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.title('Training and Validation Loss')\n",
        "plt.legend()\n",
        "\n",
        "## Plot Accuracy\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(epochs, history['train_acc'], label='Training Accuracy')\n",
        "plt.plot(epochs, history['val_acc'], label='Validation Accuracy')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.title('Training and Validation Accuracy')\n",
        "plt.legend()\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "H1JvZL8BJSgL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Saving The Model**"
      ],
      "metadata": {
        "id": "9GnO-NfFJii0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## Saving the model\n",
        "# torch.save(model.state_dict(), 'Container_classifier_SGD_model.pth')\n",
        "torch.save(model.state_dict(), 'Container_cls_Adam_10Ep_sz1024_model.pth')"
      ],
      "metadata": {
        "id": "MfSD0ymGV3PS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "El20fxoXk2HB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "gXVychRbk2RV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "jemvWQRwk2cy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "c4X2AOJmk2pR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Loading the model\n",
        "loaded_model = SimpleCNN()\n",
        "loaded_model.load_state_dict(torch.load('Container_cls_Adam_10Ep_sz1024_model.pth'))\n",
        "print(loaded_model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 203
        },
        "id": "jqA7bRnReyBg",
        "outputId": "571b2b9c-aea8-4561-bdbe-2467c8937a8a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'SimpleCNN' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-10-52d5acdb1ebe>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m## Loading the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mloaded_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSimpleCNN\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mloaded_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_state_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Container_cls_Adam_10Ep_sz1024_model.pth'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloaded_model\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'SimpleCNN' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# checkpoint = torch.load('Container_cls_Adam_60Ep_model.pth')\n",
        "# print(checkpoint.keys())  ## Prints all the keys in the state_dictcheckpoint"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "33sni8lXvtSf",
        "outputId": "54b75790-be1f-4719-cc41-a820c102c99f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-20-c4d0a7de7176>:1: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  checkpoint = torch.load('Container_cls_Adam_60Ep_model.pth')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "odict_keys(['conv1.weight', 'bn1.weight', 'bn1.bias', 'bn1.running_mean', 'bn1.running_var', 'bn1.num_batches_tracked', 'layer1.0.conv1.weight', 'layer1.0.bn1.weight', 'layer1.0.bn1.bias', 'layer1.0.bn1.running_mean', 'layer1.0.bn1.running_var', 'layer1.0.bn1.num_batches_tracked', 'layer1.0.conv2.weight', 'layer1.0.bn2.weight', 'layer1.0.bn2.bias', 'layer1.0.bn2.running_mean', 'layer1.0.bn2.running_var', 'layer1.0.bn2.num_batches_tracked', 'layer1.1.conv1.weight', 'layer1.1.bn1.weight', 'layer1.1.bn1.bias', 'layer1.1.bn1.running_mean', 'layer1.1.bn1.running_var', 'layer1.1.bn1.num_batches_tracked', 'layer1.1.conv2.weight', 'layer1.1.bn2.weight', 'layer1.1.bn2.bias', 'layer1.1.bn2.running_mean', 'layer1.1.bn2.running_var', 'layer1.1.bn2.num_batches_tracked', 'layer2.0.conv1.weight', 'layer2.0.bn1.weight', 'layer2.0.bn1.bias', 'layer2.0.bn1.running_mean', 'layer2.0.bn1.running_var', 'layer2.0.bn1.num_batches_tracked', 'layer2.0.conv2.weight', 'layer2.0.bn2.weight', 'layer2.0.bn2.bias', 'layer2.0.bn2.running_mean', 'layer2.0.bn2.running_var', 'layer2.0.bn2.num_batches_tracked', 'layer2.0.downsample.0.weight', 'layer2.0.downsample.1.weight', 'layer2.0.downsample.1.bias', 'layer2.0.downsample.1.running_mean', 'layer2.0.downsample.1.running_var', 'layer2.0.downsample.1.num_batches_tracked', 'layer2.1.conv1.weight', 'layer2.1.bn1.weight', 'layer2.1.bn1.bias', 'layer2.1.bn1.running_mean', 'layer2.1.bn1.running_var', 'layer2.1.bn1.num_batches_tracked', 'layer2.1.conv2.weight', 'layer2.1.bn2.weight', 'layer2.1.bn2.bias', 'layer2.1.bn2.running_mean', 'layer2.1.bn2.running_var', 'layer2.1.bn2.num_batches_tracked', 'layer3.0.conv1.weight', 'layer3.0.bn1.weight', 'layer3.0.bn1.bias', 'layer3.0.bn1.running_mean', 'layer3.0.bn1.running_var', 'layer3.0.bn1.num_batches_tracked', 'layer3.0.conv2.weight', 'layer3.0.bn2.weight', 'layer3.0.bn2.bias', 'layer3.0.bn2.running_mean', 'layer3.0.bn2.running_var', 'layer3.0.bn2.num_batches_tracked', 'layer3.0.downsample.0.weight', 'layer3.0.downsample.1.weight', 'layer3.0.downsample.1.bias', 'layer3.0.downsample.1.running_mean', 'layer3.0.downsample.1.running_var', 'layer3.0.downsample.1.num_batches_tracked', 'layer3.1.conv1.weight', 'layer3.1.bn1.weight', 'layer3.1.bn1.bias', 'layer3.1.bn1.running_mean', 'layer3.1.bn1.running_var', 'layer3.1.bn1.num_batches_tracked', 'layer3.1.conv2.weight', 'layer3.1.bn2.weight', 'layer3.1.bn2.bias', 'layer3.1.bn2.running_mean', 'layer3.1.bn2.running_var', 'layer3.1.bn2.num_batches_tracked', 'layer4.0.conv1.weight', 'layer4.0.bn1.weight', 'layer4.0.bn1.bias', 'layer4.0.bn1.running_mean', 'layer4.0.bn1.running_var', 'layer4.0.bn1.num_batches_tracked', 'layer4.0.conv2.weight', 'layer4.0.bn2.weight', 'layer4.0.bn2.bias', 'layer4.0.bn2.running_mean', 'layer4.0.bn2.running_var', 'layer4.0.bn2.num_batches_tracked', 'layer4.0.downsample.0.weight', 'layer4.0.downsample.1.weight', 'layer4.0.downsample.1.bias', 'layer4.0.downsample.1.running_mean', 'layer4.0.downsample.1.running_var', 'layer4.0.downsample.1.num_batches_tracked', 'layer4.1.conv1.weight', 'layer4.1.bn1.weight', 'layer4.1.bn1.bias', 'layer4.1.bn1.running_mean', 'layer4.1.bn1.running_var', 'layer4.1.bn1.num_batches_tracked', 'layer4.1.conv2.weight', 'layer4.1.bn2.weight', 'layer4.1.bn2.bias', 'layer4.1.bn2.running_mean', 'layer4.1.bn2.running_var', 'layer4.1.bn2.num_batches_tracked', 'fc.0.weight', 'fc.0.bias', 'fc.3.weight', 'fc.3.bias', 'fc.6.weight', 'fc.6.bias', 'fc.8.weight', 'fc.8.bias'])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.save(model, 'model.pth')"
      ],
      "metadata": {
        "id": "x-zXvrf7vZUs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# import torch\n",
        "# from torchvision import models, transforms\n",
        "# from PIL import Image\n",
        "\n",
        "# # Load the saved model\n",
        "# model = models.resnet18(pretrained=True)\n",
        "# model.fc = nn.Linear(model.fc.in_features, 1000)  # Adjust to match the original model's output units\n",
        "# model.load_state_dict(torch.load('Container_cls_Adam_10Ep_sz1024_model.pth'))\n",
        "# model.eval()\n",
        "\n",
        "# # Create a new model with the correct final layer\n",
        "# new_model = models.resnet18(pretrained=True)\n",
        "# new_model.fc = nn.Linear(new_model.fc.in_features, 4)  # Adjust to match the desired output units\n",
        "\n",
        "# Copy the weights and biases from the loaded model to the new model\n",
        "# new_model.layer4.0.conv1.weight.data = model.layer4.0.conv1.weight.data[0:2]\n",
        "# new_model.layer4.0.bn1.weight.data = model.layer4.0.bn1.weight.data[0:2]\n",
        "# new_model.layer4.0.bn1.bias.data = model.layer4.0.bn1.bias.data[0:2]\n",
        "# new_model.layer4.0.conv2.weight.data = model.layer4.0.conv2.weight.data[0:2]\n",
        "# new_model.layer4.0.bn2.weight.data = model.layer4.0.bn2.weight.data[0:2]\n",
        "\n",
        "# new_model.layer4.0.bn2.bias.data = model.layer4.0.bn2.bias.data[0:2]\n",
        "# new_model.layer4.0.downsample.0.weight.data = model.layer4.0.downsample.0.weight.data[0:2]\n",
        "\n",
        "\n",
        "# new_model.layer4.0.downsample.1.weight.data = model.layer4.0.downsample.1.weight.data[0:2]\n",
        "# new_model.layer4.0.downsample.1.bias.data = model.layer4.0.downsample.1.bias.data[0:2]\n",
        "# new_model.layer4.1.conv1.weight.data = model.layer4.1.conv1.weight.data[0:2]\n",
        "# new_model,layer4.1.bn1.weight.data = model.layer4.1.bn1.weight.data[0:2]\n",
        "# new_model.layer4.1.bn1.bias.data = model.layer4.1.bn1.bias.data[0:2]\n",
        "# new_model.layer4.1.conv2.weight.data = model.layer4.1.conv2.weight.data[0:2]\n",
        "# new_model.layer4.1.bn2.weight.data = model.layer4.1.bn2.weight.data[0:2]\n",
        "# new_model.layer4.1.bn2.bias.data = model.layer4.1.bn2.bias.data[0:2]\n",
        "\n",
        "# new_model.fc.weight.data = model.fc.weight.data[0:2]  # Copy only the first 2 output units\n",
        "# new_model.fc.bias.data = model.fc.bias.data[0:2]"
      ],
      "metadata": {
        "id": "Hb84QbLYwRFW",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 445
        },
        "outputId": "43997ef3-507c-43ac-aec9-2577592b7aad"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-14-952799b4441c>:8: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  model.load_state_dict(torch.load('Container_cls_Adam_10Ep_sz1024_model.pth'))\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "Error(s) in loading state_dict for ResNet:\n\tMissing key(s) in state_dict: \"fc.weight\", \"fc.bias\". \n\tUnexpected key(s) in state_dict: \"fc.0.weight\", \"fc.0.bias\", \"fc.3.weight\", \"fc.3.bias\", \"fc.6.weight\", \"fc.6.bias\", \"fc.8.weight\", \"fc.8.bias\". ",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-14-952799b4441c>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresnet18\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpretrained\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0min_features\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1000\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Adjust to match the original model's output units\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_state_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Container_cls_Adam_10Ep_sz1024_model.pth'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mload_state_dict\u001b[0;34m(self, state_dict, strict, assign)\u001b[0m\n\u001b[1;32m   2582\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2583\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merror_msgs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2584\u001b[0;31m             raise RuntimeError(\n\u001b[0m\u001b[1;32m   2585\u001b[0m                 \"Error(s) in loading state_dict for {}:\\n\\t{}\".format(\n\u001b[1;32m   2586\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"\\n\\t\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merror_msgs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: Error(s) in loading state_dict for ResNet:\n\tMissing key(s) in state_dict: \"fc.weight\", \"fc.bias\". \n\tUnexpected key(s) in state_dict: \"fc.0.weight\", \"fc.0.bias\", \"fc.3.weight\", \"fc.3.bias\", \"fc.6.weight\", \"fc.6.bias\", \"fc.8.weight\", \"fc.8.bias\". "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Model Summary**"
      ],
      "metadata": {
        "id": "LnKbv40TLn7u"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "8--BehfIUkud"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# import torch\n",
        "# from torchvision import transforms\n",
        "# from PIL import Image\n",
        "\n",
        "# import torch\n",
        "# import torch.nn as nn\n",
        "# from torchvision import models\n",
        "# from torchvision.transforms import Compose, Resize, ToTensor, Normalize\n",
        "# from PIL import Image\n",
        "\n",
        "# # Step 1: Define the model architecture\n",
        "# class ContainerClassifier(nn.Module):\n",
        "#     def __init__(self, num_classes=4):\n",
        "#         super(ContainerClassifier, self).__init__()\n",
        "#         self.backbone = models.resnet18(pretrained=False)\n",
        "#         self.backbone.fc = nn.Sequential(\n",
        "#             nn.Linear(512, 256),\n",
        "#             nn.ReLU(),\n",
        "#             nn.Dropout(0.5),\n",
        "#             nn.Linear(256, 128),\n",
        "#             nn.ReLU(),\n",
        "#             nn.Dropout(0.5),\n",
        "#             nn.Linear(128, num_classes),\n",
        "#             nn.Softmax(dim=1)\n",
        "#         )\n",
        "\n",
        "#     def forward(self, x):\n",
        "#         return self.backbone(x)\n",
        "\n",
        "# # Step 2: Create an instance of the model and load weights\n",
        "# model = ContainerClassifier(num_classes=4)\n",
        "# model.load_state_dict(torch.load('Container_cls_Adam_60Ep_model.pth'), strict=False)\n",
        "# model.eval()\n",
        "\n",
        "# # Step 3: Define preprocessing for input images\n",
        "# transform = Compose([\n",
        "#     Resize((256, 256)),  # Resize to match input size\n",
        "#     ToTensor(),\n",
        "#     Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])  # Normalize for ResNet\n",
        "# ])\n",
        "\n",
        "# # Step 4: Load and preprocess an image\n",
        "# image_path = '/content/drive/MyDrive/Resnet18/Test/img0005.jpg'  # Path to your test image\n",
        "# image = Image.open(image_path).convert('RGB')  # Open and convert to RGB\n",
        "# input_tensor = transform(image).unsqueeze(0)  # Add batch dimension\n",
        "\n",
        "# # Step 5: Perform inference\n",
        "# with torch.no_grad():\n",
        "#     output = model(input_tensor)\n",
        "#     predicted_class = torch.argmax(output, dim=1).item()\n",
        "\n",
        "# print(f\"Predicted Class: {predicted_class}\")\n",
        "\n",
        "\n",
        "\n",
        "# ['Clean', 'Garbage', 'Incomplete', 'Not Clean']\n",
        "# Map class index to label (if applicable)\n",
        "# class_labels = {0: \"Clean\", 1: \"Garbage\", 2: \"Incomplete\", 3: \"Not Clean\"}\n",
        "# print(f\"Predicted class: {class_labels[predicted_class.item()]}\")\n"
      ],
      "metadata": {
        "id": "5XBBQRV_hhqZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "22672e70-6905-494a-9e58-8ed8af8ed7ff"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicted Class: 3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-22-c953d83df7cd>:32: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  model.load_state_dict(torch.load('Container_cls_Adam_60Ep_model.pth'), strict=False)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "54u__HlhMXNL"
      },
      "source": [
        "<!--  -->"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}